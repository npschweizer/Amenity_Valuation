---
title: "Overview"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

As most new AirBnb landlords will tell you, there's a lot of stuff you can buy to try to spruce up your property and almost as many [YouTube personalities](https://www.youtube.com/watch?v=WwsMIChMDfE), [news articles](https://qz.com/810309/you-can-earn-10-more-per-night-on-airbnb-just-by-having-a-hair-dryer/) and [blogs](https://optimizemybnb.com/improve-airbnb-amenities/) telling you to do the same. Even AirBnb has released [analysis](https://www.airbnb.com/resources/hosting-homes/a/the-best-amenities-to-offer-right-now-203) (although no data) to try to help guide landlords trying to decide how or whether to improve their listings.

Motivated by my own frustration with trying to guess what amenities are worth getting, I'm going to try to walk you through some of the factors you might want to consider when preparing your listing for rental. There'll be fancy data science predictions at the end, but I recommend reading the middle stuff since it's pretty useful even if slightly more pedestrian.


# Caveats


_Dataset sourced from Mashvisor via RapidAPI._
_This project only contains data on listings for properties rented in their entirety in the Philadelphia marketplace. It does not contain listings for individual rooms or shared rooms._


```{r setup, include=FALSE}
###Run Me First
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
setwd("~/Projects/Ammenity_Valuation")
df_l0 = read.csv("l0_detailed_listings.csv", stringsAsFactors = TRUE, header = TRUE)
df_l1 = read.csv("l1_detailed_listings.csv", stringsAsFactors = TRUE, header = TRUE)
df_l2 = read.csv("l2_detailed_listings.csv", stringsAsFactors = TRUE, header = TRUE)
df_l3 = read.csv("l3_detailed_listings.csv", stringsAsFactors = TRUE, header = TRUE)
df_l4 = read.csv("l4_detailed_listings.csv", stringsAsFactors = TRUE, header = TRUE)
df_amenities_pre = read.csv("l0_amenities.csv", stringsAsFactors = TRUE, header = TRUE)
df_amenities = read.csv("l1_amenities.csv", stringsAsFactors = TRUE, header = TRUE)
library(dplyr)
library(ggplot2)
library(corrplot)
library(caret)
library(lubridate)
library(ISLR)
library(glmnet)
library(shiny)
library(shinydashboard)
library(naniar)
if( "user_id" %in% colnames(df_l1)){
  df_l1$user_id = factor(df_l1$user_id)
  df_l1$user_id = NULL}
if( "zipcode" %in% colnames(df_l1)){
  df_l1$zipcode = factor(df_l1$zipcode)}
if( "neighborhood" %in% colnames(df_l1)){
  df_l1$neighborhood = factor(df_l1$neighborhood)}
df_l1$rooms = df_l1$bedrooms + df_l1$bathrooms
df_l0$created_at=as.Date(df_l0$created_at)
df_l0$updated_at=as.Date(df_l0$updated_at)
```

# EDA
The dataset began with 1497 observations of 283 features, many of which were irrelevant to the project or redundant.
```{r data_shape, echo = FALSE}
print("Column Names")
colnames(df_amenities_pre)

```

Price, rental income, and occupancy all appear to be normally distributed, with obvious outliers. AirBnb is a roomsharing platform for landowners so it may be reasonable to attribute the frequency of occupancy rates between 0 and 25% to owners who don't rent out their properties full-time. Median rental income for a Philadelphia Airbnb over this period was $1610, occupancy was 52%, and price was $104. By comparison, rentcafe.com suggests that mean rent for a single bedroom apartment in Philadelphia is $1660/month. 
```{r distributions, echo =FALSE}
df_l1 %>%ggplot(aes(x = rental_income)) + geom_histogram(binwidth = 100)
df_l1 %>%ggplot(aes(x = occupancy)) +geom_histogram()
df_l1 %>%ggplot(aes(x = price)) + geom_histogram(binwidth = 50)

```

The number of properties managed by a host appeared to significantly vary with rental income, although the effect isn't strictly linear. Property count doesn't correlate substantially with any other numerical variable in the dataset and it's introduction appears to dramatically reduce overfit in linear modeling.
```{r user_count, echo= FALSE}
df_host = df_l1%>%group_by(host_id)%>%
  summarise(count=n())
df_l1=left_join(df_l1, df_host, by= "host_id")
```

```{r user_count_plot, echo=FALSE}
df_l2 %>%
  ggplot(aes(x=Number.of.Properties.Hosted, y=rental_income/Bedrooms))+
  geom_smooth() + 
  geom_point()

df_l2 %>%
  ggplot(aes(x=Number.of.Properties.Hosted)) + 
  geom_histogram()

df_l2 %>%
  ggplot(aes(x=Number.of.Properties.Hosted, y=rental_income))+
  geom_smooth() + 
  geom_point()

plot(lm(rental_income ~Number.of.Properties.Hosted, data=df_l2)) 

df_cort=data.frame(df_l2%>% select_if(is.numeric)%>%cor(use="pairwise.complete.obs"))
df_cort['Number.of.Properties.Hosted']
```


Unsurprisingly, larger properties appear to earn more, although it's important to remember that more income != more profit.

# Rooms and Rental Income
```{r rooms, echo = FALSE}

df_l1%>%
  #filter(level == 2)%>%
  group_by(bedrooms)%>%
  summarise(Median_income = median(rental_income),
            Standard_Dev = sd(rental_income))


df_l1%>%
  #filter(level == 2)%>%
      ggplot(aes(y = rental_income, x = bedrooms)) +
      geom_point() +
      geom_smooth() +
      ylab("Monthly Income per Listing") + 
      xlab("# of Rooms per Listing")+
      xlim(0,9) +
      scale_x_continuous(breaks=seq(0,9,1))


```

# Neighborhood and Rental Income
```{r neighborhood, echo = FALSE}
df_l1 %>%
      group_by(neighborhood)%>%
      #filter(level == 2)%>%
      filter(n()>10)%>%
      ggplot(aes(x = reorder(neighborhood,rental_income, median),
                 y = rental_income)) +
      geom_boxplot() +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
      ylim(0,10000) +
      xlab("Neighborhood") +
      ylab("Monthly Rental Income")

df_l1 %>%
      group_by(neighborhood)%>%
      #filter(level == 2)%>%
      filter(n()>10)%>%
      ggplot(aes(x = reorder(neighborhood,price, median),
                 y = price)) +
      geom_boxplot() +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
      ylim(0,500) +
      xlab("Neighborhood") +
      ylab("Nightly Price")

df_l1 %>%
      group_by(neighborhood)%>%
      #filter(level == 2)%>%
      filter(n()>10)%>%
      ggplot(aes(x = reorder(neighborhood,listing_weekend_price_native, median),
                 y = listing_weekend_price_native)) +
      geom_boxplot() +
      theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
      ylim(0,500)+
      xlab("Neighborhood") +
      ylab("Weekend Nightly Price")
      
```

Interestingly, even though the dataset included rentals from before and after the initiation of the COVID19 quarantine in Philadelphia, listing created shortly before the quarantine didn't seem to perform much worse than listings created after the quarantine
```{r creation_date, echo=FALSE}
lims <- as.POSIXct(strptime(c("2020-02-23 00:00", "2020-10-24 00:00"), 
                   format = "%Y-%m-%d %H:%M"))
ggplot(data=df_l0, aes(x= created_at, y=rental_income)) +geom_point() +
  scale_x_date(date_breaks="1 week", date_labels="%W") +
  xlim(as.Date("2019-12-05"), as.Date("2020-10-20"))
ggplot(data=df_l0, aes(x= created_at, y=occupancy)) +geom_point() + 
  scale_x_date(date_breaks="1 week", date_labels="%W") + xlim(as.Date("2019-12-05"), as.Date("2020-10-20"))


```


Some amenities are a lot more common than others. As you can see below, while a few amenities were present in almost every property, most amenities were listed in less than 25% of listings and no small number were available in less than 5% of listings.
```{r frequent_amenities, echo = FALSE}
totals = colSums(df_amenities_pre)
totalnames = colnames(df_amenities_pre)
df_amsums = data_frame(totalnames, totals)
df_amsums = df_amsums%>% arrange(desc(totals))
df_amsums%>%filter(totals> quantile(totals, .75) ) %>%
  ggplot()+
  geom_bar(aes(x = reorder(totalnames, desc(totals)), y = (totals/nrow(df_amsums)/10)), stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  coord_flip()+
  ylab("Percentage of Listings w/ Amenity")+
  xlab("Amenity")

```

This is a major consideration and something you should consider independent of income predictions - if an amenity is particularly rare or exceedingly common then chances are the my modeling isn't as accurate as I'd like and you'd be skip the fancy data voodoo and simply ask yourself how much more you'd pay to stay in a listing with the item you're thinking about getting. If you wouldn't pay an extra \$20 a night to stay in a listing with a hot tub, then maybe shelling out $5k for one isn't a great investment. Conversely, if you've met a lot of pruny-feet enthusiasts who decry the paucity of suitable listings in Philly, you might be on to something.
```{r infrequent_amenities, echo = FALSE}
totals = colSums(df_amenities_pre)
totalnames = colnames(df_amenities_pre)
df_amsums = data_frame(totalnames, totals)
df_amsums = df_amsums%>% arrange(desc(totals))
df_amsums%>%filter(totals< quantile(totals, .25) ) %>%
  ggplot()+
  geom_bar(aes(x = reorder(totalnames, desc(totals)), y = (totals/nrow(df_amsums))), stat = "identity")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  coord_flip()+
  ylab("Percentage of Listings w/ Amenity") +
  xlab("Amenity")

```
```{r var_amenity_count, echo=FALSE}
amnames = c()
for(ams in 1:length(df_amenities)){
  if(colnames(df_amenities[ams]) %in% colnames(df_l2) ){
  amnames =append(amnames, colnames(df_amenities[ams]))}
}
df_l2$amenity_count = rowSums(df_l2[amnames])
```

After variance drops I evaluated the number of amenities offered per listing, below. 

```{r amenity distribution, echo = FALSE}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

df_l2 %>%
  #filter(level == 2)%>%
  ggplot(aes(x = amenity_count)) +
  geom_histogram() + 
  ggtitle("Distribution of Amenities per Listing") +
  xlab("# of Amenities Offered per Listing")+
  geom_vline(aes(xintercept=median(amenity_count)),
            color="blue", linetype="dashed", size=1)+
  
   geom_text(aes(x=median(amenity_count), y = 100, label="\nMedian"), color="blue", angle = 270, text=element_text(size=11)) +
  
  geom_text(aes(x = getmode(amenity_count), y = 100, label = "\nMode"), color = "red", angle = 270, text=element_text(size=11))+
  
  geom_vline(aes(xintercept=getmode(amenity_count)),
            color="red", linetype="dashed", size=1)

```

There seems to be a positive relationship between the number of amenities a listing offers and number of rooms (bathrooms plus bedrooms) per listing or the price of the listing, respectively. 

```{r rooms_amenity_count, echo = FALSE}

df_l2 %>%
  #filter(level == 2)%>%
  ggplot(aes(y = amenity_count, 
             x = (Bathrooms + Bedrooms))) +
  geom_smooth() +
  geom_point(position = "jitter", color = "orange", size = 0.1, stroke = 0, shape = 16)+
 # ylim(0,10000) +
  ylab("# of Amenities per Listing") +
  xlab("# of Rooms Offered per Listing")+
  ggtitle("# of Rooms per Listing vs # of Amenities per Listing")+ 
  xlim(0,9)
```

And, in general, properties that have more amenities appear to charge slightly more.

```{r price_amenity_count, echo = FALSE}
df_l2 %>%
  #filter(level == 2)%>%
  ggplot(aes(y = Nightly.Price, 
             x = amenity_count)) +
  geom_smooth() +
  geom_point(position = "jitter", size = 0.1, stroke = 0, color = "orange")+
  ylim(0,1000) +
  ylab("Nightly Price") +
  xlab("# of Amenities Offered per Listing")+
  ggtitle("Nightly Price vs # of Amenities per Listing")
```
However, when related to rental income or occupancy, the number of amenities seems to be positively related only within specific tolerances. This may suggest that above a certain threshold, more amenities only overwhelm potential travelers, or, below a certain threshold, communicate disinterest on the part of the host, although limited data at particularly high or low counts creates substantial uncertainty. Of note, adding amenity count to penalized linear modeling appeared to greatly increase overfitting.


```{r disp_amenity_count, echo = FALSE}
#library(pdp)
#library(randomForest)
df_l2 %>%
  #filter(level == 2)%>%
  ggplot(aes(y = rental_income, 
             x = amenity_count)) +
  geom_smooth() +
  geom_point(position = "jitter", size = 0.1, stroke = 0, color = "orange")+
  ylim(0,10000) +
  ylab("Rental Income") +
  xlab("# of Amenities Offered per Listing")+
  ggtitle("Monthly Rental Income vs # of Amenities per Listing")
df_l2 %>%
  #filter(level == 2)%>%
  ggplot(aes(y = occupancy, 
             x = amenity_count)) +
  geom_smooth() +
  geom_point(position = "jitter", size = 0.1, stroke = 0, color = "orange")+
#  ylim(0,10000) +
  ylab("Occupancy") +
  xlab("# of Amenities Offered per Listing")+
  ggtitle("Occupancy vs # of Amenities per Listing")
#rf.listing500 = randomForest( X[train,] , y[train], importance = TRUE, ntree = 500    
#partial(rf.listing500, pred.var = "amenity_count",
#             plot = TRUE, train = X,  plot.engine = "ggplot2")

plot(lm(rental_income ~ amenity_count, data=df_l2))

```

# Multicolinearity
One issue I dealt with working with this data set was the sheer number of variables, which you can get a sense of from the corrplot below.
```{r multicolinearity, echo = FALSE}
library(RColorBrewer)
cc = df_l2%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(!amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
cc0 <- cc
diag(cc0) <- 0
ok <- apply(abs(cc0) >= threshold, 1, any)
cc = cc[ok, ok]


               corrplot(cc,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             tl.cex = .1,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )
```

Even when we examine amenities only and drop variables with a near-zero variance, we still have a lot of variables to work with. However, we can begin to get the sense of some clusters of related variables within the dataset.
```{r ammulticolinearity, echo = FALSE}
cca = df_amenities%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
cca0 <- cca
diag(cca0) <- 0
ok <- apply(abs(cca0) >= threshold, 1, any)
cca = cca[ok, ok]


               corrplot(cca,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )


```

We see a fairly high correlation between certain categories of children's amenities (Baby baths with changing tables, for example), but not necessarily others (see changing tables and bathtubs), suggesting that owners may view some mixes of amenities as redundant.

```{r child, echo=FALSE}
childstring = c("Baby.bath","Baby.monitor","Babysitter.recommendations",
                          "Changing.table","Children.s.books.and.toys","Children.s.dinnerware",
                          "Crib","Family.kid.friendly" ,"High.chair","Outlet.covers",
                          "Pack..n.Play.travel.crib","Playground",
                          "Table.corner.guards","Fireplace.guards","Playground","Bathtub")

df_child = df_amenities[(names(df_amenities) %in% childstring)]


#df_child%>%
#  ggplot(aes(x = as.factor(ChildScore))) +
#  geom_histogram(stat = "count")
#colSums(df_child)

ccc = df_child%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
ccc0 <- ccc
diag(ccc0) <- 0
ok <- apply(abs(ccc0) >= threshold, 1, any)
ccc = ccc[ok, ok]


               corrplot(ccc,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             #tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )



```

We also see correlations between access-related amenities that correspond to different locations within the listing, suggesting some possible redundancy in listings or that landlords are willing to make their properties more accessible when possible, but possibly unwilling or unable to ensure complete accessibility in many instances.
```{r access, echo = FALSE}


amstring = c("Accessible.height.bed" ,"Accessible.height.toilet",
                           "Elevator", "Extra.space.around.bed", "Fixed.grab.bars.for.shower",
                           "Flat.path.to.guest.entrance", "Handheld.shower.head",
                           "No.stairs.or.steps.to.enter", "Roll.in.shower", 
                           "Wheelchair.accessible", "Well.lit.path.to.entrance", "Wide.entrance",
                           "Wide.doorway.to.guest.bathroom", "Wide.clearance.to.shower", 
                           "Wide.entrance.for.guests" ,"Wide.entryway", "Wide.hallways")

df_access = df_amenities[(names(df_amenities) %in% amstring)]

ccac = df_access%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
ccac0 <- ccac
diag(ccac0) <- 0
ok <- apply(abs(ccac0) >= threshold, 1, any)
ccac = ccac[ok, ok]


               corrplot(ccac,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             #tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )

```

Not a lot of relationships here. Everything presumed incidental.

```{r essentials, echo = FALSE}

cstring = c("Shampoo", "Shower.gel", "Conditioner", "Extra.pillows.and.blankets", "Hair.dryer" , 
                           "Hangers", "Iron", "Private.entrance", "Private.living.room", "Lock.on.bedroom.door", 
                           "Air.conditioning", "Heating", "Portable.fans", "Ceiling.fan","Laundromat.nearby","Hot.water",
                           "Ethernet.connection","Pocket.wifi","Laptop.friendly.workspace" ,
                           "TV","Cable.TV","Record.player","Sound.system","Indoor.fireplace" 
                           )

df_common = df_amenities[(names(df_amenities) %in% cstring)]

ccco = df_common%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
ccco0 <- ccco
diag(ccco0) <- 0
ok <- apply(abs(ccco0) >= threshold, 1, any)
ccco = ccco[ok, ok]


               corrplot(ccco,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             #tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )
```

Lots of obvious relationships in the kitchen - listings with ovens tend to have stoves, cooking basics, microwaves, and refrigerators and there's a strong relationship between microwave and coffee machines. Interestingly, there isn't much of a relationship between listings that offer a Keurig or pour-over coffee and more complete kitchen amenities, suggesting that these may be more frequently offered in listings that offer a small coffee/snack station but not a full-service kitchen, or, alternatively, that owners aren't very specific about the kinds of coffee in their listings.

```{r kitchen, echo=FALSE}



kstring = c("Microwave","Cooking.basics", "Coffee.maker", "Nespresso.machine" , "Pour.Over.Coffee", 
                            "Keurig.coffee.machine", 
                            "Refrigerator", "Mini.fridge", "Freezer", "Dishwasher", "Trash.compacter", "Dishes.and.silverware",
                            "Stove", "Oven", "Bread.maker", "Refrigerator", "Baking.sheet" , "Barbecue.utensils", "Rice.Maker",
                            "Baking.sheet", "Convection.oven", "Espresso.machine", "Full.kitchen", "Kitchen","Kitchenette", "Nespresso.machine",
                            "Pour.Over.Coffee")
df_kitchen = df_amenities[(names(df_amenities) %in% kstring)]


cck = df_kitchen%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
cck0 <- cck
diag(cck0) <- 0
ok <- apply(abs(cck0) >= threshold, 1, any)
cck = cck[ok, ok]


               corrplot(cck,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             #tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )

```

Amenities "Full Kitchen" and "Kitchenette" only apear on listings that also have "Kitchen", suggesting that they are probably modifiers on the "Kitchen" feature.

```{r kit, echo=TRUE}

df_l1%>%filter(Kitchen == 1)%>%
  summarise(Kitchens=n())

df_l1%>%filter(Full.kitchen == 1)%>%
  summarise(Full.Kitchens=n())

df_l1%>%filter(Kitchen == 1)%>%
     filter(Full.kitchen==1)%>%
  summarise(KitchenNFullKitchen=n())

df_l1%>%filter(Kitchenette == 1)%>%
  summarise(Kitchenette=n())

df_l1%>%filter(Kitchen == 1)%>%
     filter(Kitchenette==1)%>%
  summarise(KitchenNKitchenette=n())

df_l1%>%filter(Full.kitchen == 1)%>%
     filter(Kitchenette==1)%>%
  summarise(FullKitchenNKitchenette=n())

df_kitchen%>%filter(Kitchenette==1)

```

The same thing appears to be true for ovens and convection ovens.
```{r oven, echo=TRUE}

df_l1%>%filter(Oven == 1)%>%
  summarise(Oven=n())

df_l1%>%filter(Convection.oven == 1)%>%
  summarise(Convection.oven=n())

df_l1%>%filter(Oven == 1)%>%
     filter(Convection.oven==1)%>%
  summarise(Ovens=n())

```

Some obvious correlations in facilities - listings with pools were more likely to have gyms and hottubs. Listings with gyms were less likely to offer free street parking, suggesting that they typically come in larger buildings in the city center where street parking isn't available. 

```{r fac, echo = FALSE}
fstring = c("Free.parking.on.premises", "Free.street.parking", "Paid.parking.off.premises", 
                               "Paid.parking.on.premises", "EV.charger" , "Gym", "Pool", "Hot.tub", "Single.level.home" )

df_facilities = df_amenities[(names(df_amenities) %in% fstring)]

ccf = df_facilities%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
ccf0 <- ccf
diag(ccf0) <- 0
ok <- apply(abs(ccf0) >= threshold, 1, any)
ccf = ccf[ok, ok]


               corrplot(ccf,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             #tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdBu")
              #addrect = 4
              )
```

Unsurprisingly, listings with an exterior space are more likely to own a grill.

```{r outdoor, echo=FALSE}
ostring=c("BBQ.grill", "Patio.or.balcony", "Garden.or.backyard")

df_outdoor = df_amenities[(names(df_amenities) %in% ostring)]
cco = df_outdoor%>%
               #filter(level == 2)%>%
               #select(!level)%>%
               #select(amnames)%>%
               select_if(is.numeric) %>%
               select_if(~ !any(is.na(.)))%>%
               #select(c(input$variable)) %>%
               cor() 

threshold <- 0
cco0 <- cco
diag(cco0) <- 0
ok <- apply(abs(cco0) >= threshold, 1, any)
cco = cco[ok, ok]


               corrplot(cco,
              #col = c("white", "red"),
              #bg = "lightblue",
              #method = "square",
              order = "hclust",
              type = "lower",
             #tl.cex = .2,
             col = brewer.pal(n = 12, name = "RdYlBu")
              #addrect = 4
              )

```

```{r corr, echo=FALSE}


threshold <- .7
cc0 <- cc
diag(cc0) <- 0
ok <- apply(abs(cc0) >= threshold, 1, any)
cc = cc[ok, ok]
df_cor=data.frame(cc)
df_cor
# 
#  detailed_listings = detailed_listings %>%
#    select(star_rating, everything())
#  
#  nums <- unlist(lapply(detailed_listings, is.numeric)) 
#  cors = data.frame(cor(detailed_listings[,nums], use = "na.or.complete"))
#  cors = cors%>%
#    arrange(star_rating)
```


# Imputation Graphs
After cleaning less than 1% of the dataset was null/NA. Missing values were imputed using KNN with euclidean distance used as a metric and 3-6 nearby features selected by correlation for each variable, or by imputing the median. Pre- and post-imputation distributions are available below.

```{r missings, echo = FALSE}


###Total NA Values
#missings = data.frame(name = names(colSums(is.na(df_comb %>%filter(level==1)))),
#                      missing = colSums(is.na(df_comb%>%filter(level==1))))
#missings = missings %>%
#  filter(missing>0)%>%
#  arrange(missing)

#subset <- t(data.frame(missings$missing))
#barplot(subset, legend = c("missing"), names.arg=missings$name, beside=TRUE)

l3 = df_l3
l4 = df_l4
l3$level=3
l4$level=4

df_comb=rbind(l3,l4)
#colSums(is.na(df_l3))
misses = colSums(is.na(df_comb%>%filter(level==3)))>0
#df_comb[misses]
gg_miss_var(df_comb[misses])

levnams = c("Pre-Imputation", "Post-Imputation")

###Bedrooms

#df_comb %>%
#  ggplot(aes(x = Bedrooms)) + 
#  geom_histogram() +
#  facet_grid(~level, labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation")))+
#  scale_x_continuous(name = "# of Bedrooms", breaks = seq(0,9, 1), limits = c(0,9))

###Cleaning Fee
df_comb%>%
  ggplot(aes(x = Cleaning.Fee)) + 
  geom_histogram() +
  facet_wrap(~level,labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation"))) +
  ggtitle("Distribution of Cleaning Fees")+
  xlim(0,250)

###Check Out Time
df_comb %>%
  ggplot(aes(x = Check.Out.Time)) + 
  geom_histogram() +
  facet_wrap(~level, labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation"))) +
  ggtitle("Distribution of Check Out Times") + 
  xlab("Check Out Time (24 Hr)") +
  xlim(0,24)

#df_comb %>%
#  group_by(level,check_out_time)%>%
#  summarise(count = n())

###Security Deposits
df_comb %>%
  ggplot(aes(x = Security.Deposit)) + 
  geom_histogram(binwidth = 10) +
  facet_wrap(~level, labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation"))) +
  ggtitle("Distribution of Security Deposit Amounts") + 
  xlab("Some Outliers Eliminated") +
  xlim(-5,1000)

####Check In Time
df_comb %>%
  ggplot(aes(x = Check.In.Time)) + 
  facet_grid(~ level, labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation"))) +
  geom_histogram() +
  ggtitle("Distribution of Check In Time") + 
  xlab("Check In Time")

#df_comb %>%
#  group_by(level,X24.hour.check.in) %>%
#  summarise(missing = sum(is.na(check_in_time))/n() )


###Locale
#df_comb %>%
#  ggplot(aes(x = locale)) + 
#  geom_bar(stat = "count") +
 # facet_wrap(~level, labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation")))

#df_comb %>%
#  group_by(level,locale)%>%
#  summarise(count = n())

###Last Update
if( "updated_at" %in% colnames(df_comb)){
df_comb %>%
  ggplot(aes(x = updated_at)) + 
  geom_freqpoly(stat = "count") +
  facet_wrap(~level, labeller = labeller(level = c('3' = "Pre-Imputation", '4' = "Post-Imputation"))) +
  ggtitle("Time of Last Update") + 
  xlab("All Dates 2020")}

```


#ANOVA Drops
ANOVA testing was used to eliminate zipcode and city on the basis of inadquate variance. "is_location_exact", "description_locale", "require_guest_phone_verification", "instant_bookable" and "require_guest_phone_verification" were dropped for similar reasons.

```{r ANOVA_drops, echo = TRUE}
summary(aov(rental_income ~ zipcode , data = df_l0)) 
summary(aov(price ~ zipcode , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ zipcode , data = df_l0)) 

summary(aov(rental_income ~ city , data = df_l0)) 
summary(aov(price ~ city , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ city , data = df_l0)) 

summary(aov(rental_income ~ city , data = df_l0)) 
summary(aov(price ~ city , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ city , data = df_l0))

summary(aov(rental_income ~ bed_type_category , data = df_l0)) 
summary(aov(price ~ bed_type_category , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ bed_type_category , data = df_l0))
summary(aov(occupancy ~ bed_type_category , data = df_l0))


summary(aov(rental_income ~ require_guest_phone_verification , data = df_l0)) 
summary(aov(price ~ require_guest_phone_verification , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ require_guest_phone_verification , data = df_l0))
summary(aov(occupancy ~ require_guest_phone_verification , data = df_l0))

summary(aov(rental_income ~ is_location_exact , data = df_l0)) 
summary(aov(price ~ is_location_exact , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ is_location_exact , data = df_l0))
summary(aov(occupancy ~ is_location_exact , data = df_l0))

summary(aov(rental_income ~ instant_bookable , data = df_l0)) 
summary(aov(price ~ instant_bookable , data = df_l0))
summary(aov(listing_weekend_price_native ~ instant_bookable , data = df_l0))
summary(aov(occupancy ~ instant_bookable , data = df_l0))

summary(aov(rental_income ~ require_guest_profile_picture , data = df_l0)) 
summary(aov(price ~ require_guest_profile_picture , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ require_guest_profile_picture , data = df_l0))
summary(aov(occupancy ~ require_guest_profile_picture , data = df_l0))

summary(aov(rental_income ~ description_locale , data = df_l0)) 
summary(aov(price ~ description_locale , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ description_locale , data = df_l0))
summary(aov(occupancy ~ description_locale , data = df_l0))

summary(aov(rental_income ~ locale , data = df_l0)) 
summary(aov(price ~ locale , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ locale , data = df_l0))
summary(aov(occupancy ~ locale , data = df_l0))

summary(aov(rental_income ~ max_nights , data = df_l0)) 
summary(aov(price ~ max_nights , data = df_l0)) 
summary(aov(listing_weekend_price_native ~ max_nights , data = df_l0))
summary(aov(occupancy ~ max_nights , data = df_l0))

```

In order to improve modeling on non-tree models I dropped amenities with near-zero variance, listed below.

```{r amdrops, echo = FALSE }
amdrops_pre = c(colnames(df_amenities_pre)) 
amdrops = c(colnames(df_amenities))
amdrops_fin = amdrops_pre[!(amdrops_pre %in% amdrops)]
amdrops_fin
```
